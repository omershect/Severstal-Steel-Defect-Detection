{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Inference_Ensemble_with_Classifcation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IVQS5br7KZb",
        "colab_type": "text"
      },
      "source": [
        "#####  Inference kernel\n",
        "* Unet Efficnet B5 \n",
        "* Unet FPN Efficnet Net  B5 \n",
        "* Classifcation based on Efficnet Net  B4 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWRv2jKr7KZg",
        "colab_type": "code",
        "colab": {},
        "outputId": "8e1f3398-4482-4f09-8664-4c89187c1c0c"
      },
      "source": [
        "import os \n",
        "os.listdir('../input/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visdom',\n",
              " 'unet-efficientb5-no-aug-11-09',\n",
              " 'effb4-classifer-fold4',\n",
              " 'fpn-effb5-softmax-22-10',\n",
              " 'segementiation-models-21-10',\n",
              " 'pre-train-models',\n",
              " 'efficentb4-one-classifer-steel-28-09',\n",
              " 'unetmodelscript',\n",
              " 'efficentnet-pytorch-0-4-0',\n",
              " 'unet-seresnet50-bcediceloss-17-09',\n",
              " 'efficientunet-pytorch-master',\n",
              " 'jsonpatch',\n",
              " 'jsonpointer',\n",
              " 'pretrainedmodels',\n",
              " 'torchnet',\n",
              " 'torchfile',\n",
              " 'severstal-steel-defect-detection']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7SCsRtR7KZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ../input/pre-train-models/pretrainedmodels-0.7.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZDC7VF71P5",
        "colab_type": "text"
      },
      "source": [
        "## Impoer libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "6Q2dhtud7KZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from albumentations import (Normalize, Compose)\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8I_xjkeFQOi",
        "colab_type": "text"
      },
      "source": [
        "## Packages installations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxwkAUEO7KZt",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4036e09-1da0-44c0-f716-fe0dd555bcdb"
      },
      "source": [
        "!pip install  ../input/efficentnet-pytorch-0-4-0/efficientnet_pytorch-0.4.0/\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /kaggle/input/efficentnet-pytorch-0-4-0/efficientnet_pytorch-0.4.0\r\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from efficientnet-pytorch==0.4.0) (1.2.0)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->efficientnet-pytorch==0.4.0) (1.16.4)\r\n",
            "Building wheels for collected packages: efficientnet-pytorch\r\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.4.0-cp36-none-any.whl size=11149 sha256=b049746a9159d99fe2f16cb403e801813748e67be1dbbd4d1de432afdc6aa95f\r\n",
            "  Stored in directory: /tmp/.cache/pip/wheels/04/23/e5/4506db52c387551dc1f91890f85a32161efce173622092ffe1\r\n",
            "Successfully built efficientnet-pytorch\r\n",
            "Installing collected packages: efficientnet-pytorch\r\n",
            "Successfully installed efficientnet-pytorch-0.4.0\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFOxsDl77KZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "package_path = '../input/efficientpytorch/'\n",
        "sys.path.append(package_path)\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qk_xN5f7KZx",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7a398bd-a524-4466-9611-a616eda34feb"
      },
      "source": [
        "!  pip install   \"../input/segementiation-models-21-10/segmentation_models.pytorch-master/segmentation_models.pytorch-master/\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /kaggle/input/segementiation-models-21-10/segmentation_models.pytorch-master/segmentation_models.pytorch-master\r\n",
            "Requirement already satisfied: torchvision<=0.4.0,>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from segmentation-models-pytorch==0.0.3) (0.4.0a0+6b959ee)\r\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.6/site-packages (from segmentation-models-pytorch==0.0.3) (0.7.4)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (1.16.4)\r\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (1.12.0)\r\n",
            "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (1.2.0)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (5.4.1)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.0.3) (4.36.1)\r\n",
            "Requirement already satisfied: munch in /opt/conda/lib/python3.6/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.0.3) (2.3.2)\r\n",
            "Building wheels for collected packages: segmentation-models-pytorch\r\n",
            "  Building wheel for segmentation-models-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.0.3-cp36-none-any.whl size=29146 sha256=4675211fa4c15942d01ef89966744c82c2d7322884e673019c187410703b9bd6\r\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wrerxjwe/wheels/c1/35/09/fbb62c102c3b45397fa72ef4ec30e0a91eb7c66841643e3d7a\r\n",
            "Successfully built segmentation-models-pytorch\r\n",
            "Installing collected packages: segmentation-models-pytorch\r\n",
            "Successfully installed segmentation-models-pytorch-0.0.3\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iWEVMdT7KZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import segmentation_models_pytorch as smp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9S1ucfA7KZ3",
        "colab_type": "code",
        "colab": {},
        "outputId": "77b88530-0e66-4df8-8326-24931a2cdbc1"
      },
      "source": [
        "!pip install  ../input/efficientunet-pytorch-master/EfficientUnet-PyTorch-master/\n",
        "from efficientunet import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /kaggle/input/efficientunet-pytorch-master/EfficientUnet-PyTorch-master\r\n",
            "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from efficientunet-pytorch==0.0.5) (1.2.0)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch>=1.0.0->efficientunet-pytorch==0.0.5) (1.16.4)\r\n",
            "Building wheels for collected packages: efficientunet-pytorch\r\n",
            "  Building wheel for efficientunet-pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25h  Created wheel for efficientunet-pytorch: filename=efficientunet_pytorch-0.0.5-cp36-none-any.whl size=10197 sha256=f9779f0132c647509db4430c9cefcaa69459bd416609874d34e2c95de00b62c7\r\n",
            "  Stored in directory: /tmp/.cache/pip/wheels/dc/0c/94/256e44bb61d986fb0fb17f09d52a308a328e049231d1c27dfb\r\n",
            "Successfully built efficientunet-pytorch\r\n",
            "Installing collected packages: efficientunet-pytorch\r\n",
            "Successfully installed efficientunet-pytorch-0.0.5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aHAKxNxFTXr",
        "colab_type": "text"
      },
      "source": [
        "## Mask to RLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnWVQu5i7KZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P5n7p8LFYZb",
        "colab_type": "text"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mUcfVR_7KZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    '''Dataset for test prediction'''\n",
        "    def __init__(self, root, df, mean, std):\n",
        "        self.root = root\n",
        "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "        self.fnames = df['ImageId'].unique().tolist()\n",
        "        self.num_samples = len(self.fnames)\n",
        "        self.transform = Compose(\n",
        "            [\n",
        "                Normalize(mean=mean, std=std, p=1),\n",
        "                ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fnames[idx]\n",
        "        path = os.path.join(self.root, fname)\n",
        "        image = cv2.imread(path)\n",
        "        images = self.transform(image=image)[\"image\"]\n",
        "        return fname, images\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IMKaUMBFcbC",
        "colab_type": "text"
      },
      "source": [
        "## Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnFTfNOj7KaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def post_process_class(probability, threshold, classifer):\n",
        "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
        "    than `min_size` are ignored'''\n",
        "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
        "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
        "    predictions = np.zeros((256, 1600), np.float32)\n",
        "    num = 0\n",
        "    for c in range(1, num_component):\n",
        "       p = (component == c)\n",
        "       # if p.sum() > min_size:\n",
        "       if classifer > 0.68: \n",
        "          predictions[p] = 1\n",
        "          num += 1\n",
        "    return predictions, num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmdZV-267KaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\n",
        "test_data_folder = \"../input/severstal-steel-defect-detection/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI65jzA07KaE",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b76d57d-6994-409d-f162-f44ea4670882"
      },
      "source": [
        "# initialize test dataloader\n",
        "best_threshold = 0.28\n",
        "num_workers = 2\n",
        "batch_size = 1\n",
        "print('best_threshold', best_threshold)\n",
        "min_size = 800\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "df = pd.read_csv(sample_submission_path)\n",
        "testset = DataLoader(\n",
        "    TestDataset(test_data_folder, df, mean, std),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_threshold 0.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fw5Ehdv7KaH",
        "colab_type": "text"
      },
      "source": [
        "## Segementation model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd1MzGnG7KaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ckpt_path = \"../input/unet-efficientb5-no-aug-11-09/model.pth\"\n",
        "device = torch.device(\"cuda\")\n",
        "model_seg = get_efficientunet_b5(out_channels=4, concat_input=True, pretrained=False)\n",
        "model_seg.to(device)\n",
        "model_seg.eval()\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model_seg.load_state_dict(state[\"state_dict\"])\n",
        "for param in model_seg.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ckpt_path = \"../input/fpn-effb5-softmax-22-10/weight_best_FPN_full_size_fold3_1.pt\"\n",
        "device = torch.device(\"cuda\")\n",
        "model_seg1 = smp.FPN('efficientnet-b5', classes=4 ,encoder_weights=None,activation='softmax')\n",
        "model_seg1.to(device)\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model_seg1.load_state_dict(state[\"state_dict\"])\n",
        "model_seg1.eval()\n",
        "\n",
        "for param in model_seg1.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "ckpt_path = \"../input/unet-seresnet50-bcediceloss-17-09/weight_best_256_fold2_14.pt\"\n",
        "device = torch.device(\"cuda\")\n",
        "model_seg2 = smp.Unet(\"se_resnet50\", encoder_weights=None, classes = 4 , activation=None)\n",
        "model_seg2.to(device)\n",
        "model_seg2.eval()\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model_seg2.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "for param in model_seg2.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yguv7NNp7KaM",
        "colab_type": "text"
      },
      "source": [
        "## Classifcation Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytI3f0sh7KaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class = EfficientNet.from_name('efficientnet-b4') \n",
        "in_features = model_class._fc.in_features\n",
        "model_class._fc = nn.Linear(in_features, 4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ckpt_path = \"../input/efficentb4-one-classifer-steel-28-09/weight_full_size__oneclassifer_fold2_10.pt\"\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_class.to(device)\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model_class.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_class.eval()\n",
        "\n",
        "\n",
        "\n",
        "for param in model_class.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_class1 = EfficientNet.from_name('efficientnet-b4') \n",
        "in_features = model_class1._fc.in_features\n",
        "model_class1._fc = nn.Linear(in_features, 4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ckpt_path = \"../input/effb4-classifer-fold4/weight_full_size__oneclassifer_fold46.pt\"\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model_class1.to(device)\n",
        "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
        "model_class1.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_class1.eval()\n",
        "\n",
        "\n",
        "\n",
        "for param in model_class1.parameters():\n",
        "  param.requires_grad = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TlyH6XB7KaP",
        "colab_type": "code",
        "colab": {},
        "outputId": "70c93bcb-cd6f-4f92-d614-97ca4e538aef"
      },
      "source": [
        "# start prediction\n",
        "min_size = [200,150,1000,1500] \n",
        "predictions = []\n",
        "for i, batch in enumerate(tqdm(testset)):\n",
        "    fnames, images = batch\n",
        "  \n",
        "    batch_preds_class  = torch.sigmoid(model_class(images.to(device))) \n",
        "    batch_preds_class = batch_preds_class.detach().cpu().numpy() \n",
        "\n",
        "    batch_preds_class1  = torch.sigmoid(model_class1(images.to(device))) \n",
        "    batch_preds_class1 = batch_preds_class1.detach().cpu().numpy() \n",
        "\n",
        "    \n",
        "    batch_preds_class = (batch_preds_class + batch_preds_class1)  / 2.0\n",
        "\n",
        "\n",
        "\n",
        "    batch_preds = torch.sigmoid(model_seg(images.to(device)))\n",
        "    batch_preds = batch_preds.detach().cpu().numpy()\n",
        "  \n",
        "    #batch_preds2 = torch.sigmoid(model_seg1(images.to(device)))\n",
        "    #batch_preds2 = batch_preds2.detach().cpu().numpy()\n",
        "    \n",
        "    batch_preds3 = torch.sigmoid(model_seg2(images.to(device)))\n",
        "    batch_preds3 = batch_preds3.detach().cpu().numpy()\n",
        "  \n",
        "    batch_preds = (batch_preds +  batch_preds3) / 2.0\n",
        "    #batch_preds = np.median((batch_preds,batch_preds2,batch_preds3),axis=0)  \n",
        "    \n",
        "    for fname, preds in zip(fnames, batch_preds):\n",
        "       \n",
        "        for cls, pred in enumerate(preds):\n",
        "            #pred, num = post_process(pred, best_threshold, min_size[cls])\n",
        "            pred, num = post_process_class(pred, best_threshold, batch_preds_class[0][cls])\n",
        "            rle = mask2rle(pred)\n",
        "            name = fname + f\"_{cls+1}\"\n",
        "            predictions.append([name, rle])\n",
        "\n",
        "# save predictions to submission.csv\n",
        "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
        "df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1801/1801 [05:40<00:00,  5.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aOWLLVB7KaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.head(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTpMJLMH7KaX",
        "colab_type": "text"
      },
      "source": [
        "### Refrences:\n",
        "\n",
        " \n",
        "\n",
        "* https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
        "* https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n",
        "\n",
        "A big thank you to all those who share their code on Kaggle, I'm nobody without you guys. I've learnt a lot from fellow kagglers, special shout-out to [@Abhishek](https://www.kaggle.com/abhishek), [@Yury](https://www.kaggle.com/deyury), [@Heng](https://www.kaggle.com/hengck23), [@Ekhtiar](https://www.kaggle.com/ekhtiar), [@lafoss](https://www.kaggle.com/iafoss), [@Siddhartha](https://www.kaggle.com/meaninglesslives), [@xhulu](https://www.kaggle.com/xhlulu), and the list goes on.."
      ]
    }
  ]
}